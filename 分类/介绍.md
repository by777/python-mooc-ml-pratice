### KNN

sklearn.neighbors.KNeighborsClassifier(n_neighbors=5,weights)
+ weights：设置选中的K个点对分类结果影响的权重
    （默认为平均权重uniform，可以选择distance代表越近的权重越高，或者传入自己的函数）
+ algorithm：设置计算临近点的方法，因为当数据量很大的情况下计算当前点和所有点的距离
    再选出最近的k个点，这个计算量是很费时的，所以选项中有ball_tree、kd_tree和brute，
    分别代表不同的寻找邻居的优化算法，默认为auto根据训练数据自动选择。
----------------------------------------------------------------------------
### 决策树

决策树是一种树形结构的分类器，通过顺序询问分类点的属性决定分类点最终的类别。通常根据
特征的信息增益或其它指标，构建一棵决策树。在分类时，只需要按照决策树中的节点依次进行判断
，即可得到样本的所属类别。

sklearn.tree.DecisionTreeClassifier()
+ criterion:用于选择属性的准则，可以传入'gini'代表基尼系数，或者'entropy'代表信息增益。
+ max_features:表示在决策树节点进行分裂时，从多少个特征中选择最优特征。可以设置固定数目
    、百分比或其它标准。默认值使用所有特征个数。
------------------------------------------------------------------------------
### 朴素贝叶斯

朴素贝叶斯分类器是一个以贝叶斯定理为基础的多分类的分类器。
朴素贝叶斯是典型的生成学习方法，由训练数据学习联合概率分布，并求得后验概率分布。
对于给定数据，首先基于特征的条件独立性假设，学习输入输出的联合分布概率，然后基于此模型，
对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。

+ 高斯朴素贝叶斯
+ 针对多项式模型的朴素贝叶斯分类器
+ 针对多元伯努利模型的朴素贝叶斯分类器

区别
假设某一特征的所有属于某个类别的观测值符合特定分布，如，分类问题的特征包括人的身高，
身高符合高斯分布，这类问题适合高斯朴素贝叶斯

sklearn.naive_bayes.GaussianNB()
+ priors:给定各个类别的先验概率。如果为空，则按照训练数据的实际情况进行统计。

朴素贝叶斯在小规模数据上表现很好，适合多分类任务。

